
För att testa MLP, tänkte jag prova att identifiera bilder.

Jag använder ett dataset från MNIST (http://yann.lecun.com/exdb/mnist/), med bilder av handskrivna siffror. Varje bild är 28*28 pixlar stor och i gråskala. Det finns 60 000 träningsbilder och 10 000 testbilder.

För att formulera min MLP och träna den, ska jag använda TensorFlow (https://www.tensorflow.org/get_started/get_started).

1) Testa med en enlagers perceptron, för att komma igång med TensorFlow. Skriv ut vikterna för någon siffra som en bitmap.
- Träffsäkerheten med 1000 epochs blir ca 91%. Borde hamna kring 92% enligt TensorFlows tutorial.
- Att använda en kvadratisk kostnadsfkn ger ca 2%e lägre träffsäkerhet.
- Det blev lite bättre träffsäkerhet med 10000 epochs. Kan vi använda valideringsdata för att sluta träningen när träffsäkerheten slutar sjunka?

2) Gör en tvålagers MLP och testa igen.
- Jag testade en MLP på formen y = sigmoid(W2*sigmoid(W1*x + b1) + b2), med bredden M=15 på det dolda lagret, så som föreslås i "http://neuralnetworksanddeeplearning.com/chap1.html" av Michael Nielsen.
- Jag fick ~67-77% noggranhet när jag testade, och det var ganska robust för ändringar i eta (mellan 1 och 5), om det var softmax eller sigmoid som aktiveringsfunktion i sista lagret, och vilken kostnadsfunktion jag använde (kvadratfelet eller cross-entropy). Men Neilsens bok förutsäger 95% precision. Efter ett tag hittade jag att det blev kring 93% när jag initialiserade vikterna med normalfördelade värden istf nollor. Märkligt att det är så känsligt!


3) Prova med convolutional network, enligt deras tutorial.


Allmänt:
- På vilket sätt är MNIST-bilderna förbehandlade? Det verkar som att man t.ex. har centrerat bilden kring tyngdpunkten för pixlarna, normerat gråskalan och skalat storleken.
- 
