
Labb om faltande nätverk, för att klassificera bilder
==========================================================
Bl.a. baserat på boken "Deep learning" av Goodfellow et. al.

Det finns 25 000 träningsbilder med etikett, och 12 500 testbilder utan etikett. De är avsedda för tävlingen, men jag lägger testbilderna åt sidan och avsätter 5000 träningsbilder som testdata.

Bilderna har inte samma storlek, och inte ens samma proportioner. Antingen löser jag det genom förbehandling (padda till en viss proportion och skala sedan till viss storlek), eller genom att mitt CNN får hantera bilder av olika storlek. I boken (sid 350) rekommenderar de att lägga in ett pooling-lager som varierar storleken på sina pooling-områden, för att få fast storlek på utdata.


CIFAR 10:
=============
För att få igång deras tutorial, fick jag manuellt ladda ner CIFAR 10-data från "https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz" och sen kopiera gz-filen till /home/lindhe/install/cifar10_data. Sen pekade jag om så att det blev installationskatalogen.

För att köra TensorBoard:
Kör "tensorboard --logdir=/tmp/cifar10_train" för att starta TensorBoard. Titta sedan på "localhost:6006" med webbläsaren.

Jag körde CNN-tutorialen i originalskick, och efter 14,5 timmars träning på min laptop, kom jag upp till ca 85,7% precision @ 1. Då var kostnadsfunktionen omkring 2,3 när den tränade. Se skärmdump (av en annan kostnadsfkn) i "CNN tutorial learning curve.png".

För att få igång det på seshat:
- Fixa proxyn för att kunna klona mitt git-repo:
git config --global https.proxy https://proxy.se.electrolux.com:8080
git config --global http.proxy http://proxy.se.electrolux.com:8080

- Klona mitt github-repo:
git clone https://github.com/lindhee/learning.git

- Skapa och starta en virtual environment på seshat:
virtualenv --system-site-packages ~/install/tensorflow
source ~/install/tensorflow/bin/activate

- Ange proxy inuti virtual environment:
export https_proxy="proxy.se.electrolux.com:8080"

- Installera tensorflow, version 1.5 (för 1.7 krashar med en coredump när man försöker importera den):
pip install tensorflow==1.5

- Startade en träning inuti en screen-session, med låg process-prio (se https://help.ubuntu.com/community/Screen):
screen
nice -20 python cifar10_train.py
[Tryck Ctrl+A och sen d]
logout

- Efter att ha loggat på igen:
screen -list
screen -r
Skriv sen "exit" för att avsluta screen-sessionen.

Kolla ev. in en tutorial som jag bokmärkte, som bara tar 3-4 h att träna upp.

Efter en natt på Seshat (från kl 18 till 08, dvs 14 h) var precision @ 1 = 86,8% och kostnadsfkn ungefär 0,5.

Nästa steg blir att skala bort alla bilder utom katter och hundar och träna igen.

Jag tränade med bara katter och hundar ("CIFAR 2") över en helg, och fick en kostnadsfkn på 0,02. Men precision @1 blev bara 69,9%! Hur kommer det sig? Det verkar som att testfunktionen testar på mitt decimerade dataset, så där hittar jag inget fel.

Startade en ny träningsomgång 2018-05-21T11:20 för att se om resultatet håller i sig. 2018-05-22T08:37 var kostnadsfkn 0,02 och precision @1 = 67,6%. Så det verkar ganska repeterbart.

Jag tränade CIFAR2-nätverket över en helg på seshat och fick precision @1 på 68,0%. Kostnadsfkn var 0,03. Den varianten finns sparad som referens, under cifar2_trained.

Jag tränade original-nätverket på CIFAR10-data en gång till, och sparade undan ett snapshot som referens, under cifar10_trained.

När jag testade det sparade tränade CIFAR10-nätverket på data som bara innehöll katter och hundar, fick jag precision @ 1 = 77,4%.

Sedan gjorde jag om taggarna, så att det bara fanns tre klasser: katter, hundar och övrigt, men behöll alla exempel. Jag tränade nätverket en natt, tills kostnadsfkn verkade ha konvergerat till ca 0,1, och sparade senaste checkpoint under cifar3_trained. När jag testade så fick jag precision @ 1 till 87,2%.

Hur bra presterar mitt CIFAR 3-nätverk om jag testar det på enbart hundar och katter? Jag testade nätverket med tre klasser på data med bara katter och hundar, och då fick jag precision @ 1 = 55,5%. Får jag dåliga resultat för att nätverket är tränat med 80% bilder på kategorin "övrigt", så det har en tendens att vilja välja den kategorin ofta?

Prova att slå ihop alla 4 maskiner till en kategori och 4 djur (alla utom fåglar och grodor) till en kategori. Då har vi mycket data, två lätta kategorier och lika fördelning dem emellan.

Startade en sådan träning på Seshat klockan 10:27. Klockan 18:22 var kostnadsfkn 0.01 och precision @ 1 = 94,8% !! Det stämmer med att vi har mycket data och att problemet borde vara lätt, eftersom kategorierna är så olika. Sparade sista checkpoint för det nätverket under cifar2_large_trained.

Struktur för mitt CIFAR-nätverk:
conv1: 5*5-kernel med 3 kanaler in och 64 kanaler ut, stride 2*2
conv2: 5*5-kernel med 64 kanaler in och 64 kanaler ut, stride 2*2
local3: Fullt kopplat lager med 384 neuroner
local4: Fullt kopplat lager med 192 neuroner
utsignal: Fullt kopplat lager med 10 neuroner (sedan kommer softmax, inbyggt i kostnadsfkn)




















